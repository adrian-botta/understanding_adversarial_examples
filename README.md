# understanding_adversarial_examples
A jupyter notebook containing a walkthrough of how gradient based adversarial attacks work in 2 dimensions - Including both a white-box and black-box attack.

[TBD - coming soon]

See how the jacobian-augmentation training technique helps a substitute model learn the same decision boundaries as the victim model. Technique discussed in this paper: https://arxiv.org/pdf/1602.02697.pdf

![jacobian_augmentation](https://github.com/adrian-botta/understanding_adversarial_examples/blob/master/photos/20180719_232707.gif?raw=true)
